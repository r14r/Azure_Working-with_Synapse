{
  "metadata": {
    "description": "Example analyzing and extracting insights from GitHub projects data stored in a csv.",
    "saveOutput": true,
    "language_info": {
      "name": "csharp"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GitHub Project Analysis\n",
        "In this notebook, we'll see how to use .NET for Apache Spark to analyze a file containing info about a set of GitHub projects."
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let's kick things off by starting a Spark Session\n",
        "All we need is the `spark` keyword to get our .NET for Spark app started!"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<table><thead><tr><th>SparkContext</th></tr></thead><tbody><tr><td>{ SparkContext: DefaultParallelism: 32 }</td></tr></tbody></table>"
          },
          "execution_count": 3,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "spark"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Now that we have a Spark Session, we can start writing .NET for Spark code\n",
        "We can read in our input file into a DataFrame and set its schema. Then we'll print out our DataFrame.\n",
        "\n",
        "Update the code to include the path in Azure storage to your input projects data."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "+----+--------------------+--------+--------------------+--------------------+--------+---------------+-----------+-------+-------------------+\n|  id|                 url|owner_id|                name|          descriptor|language|     created_at|forked_from|deleted|         updated_at|\n+----+--------------------+--------+--------------------+--------------------+--------+---------------+-----------+-------+-------------------+\n|   1|https://api.githu...|       1|           ruote-kit|RESTful wrapper f...|    Ruby|12/8/2009 10:17|          2|      0|     11/5/2015 1:15|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|   4|https://api.githu...|      24|             basemap|                null|     C++|6/14/2012 14:14|          3|      1|0000-00-00 00:00:00|\n|   5|https://api.githu...|      28|           cocos2d-x|Port of cocos2d-i...|     C++|3/12/2012 16:48|          6|      0|   10/22/2015 17:36|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|   7|https://api.githu...|      42|           cocos2d-x|Port of cocos2d-i...|       C|4/23/2012 10:20|          6|      0|    11/1/2015 17:32|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|   9|https://api.githu...|      66|       rake-compiler|Provide a standar...|    Ruby| 8/1/2012 18:33|   14556189|      0|    11/3/2015 19:30|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|  12|https://api.githu...|      70|heroku-buildpack-...|                null|   Shell| 8/2/2012 12:50|         11|      0|     11/2/2015 7:34|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n|null|                null|    null|                null|                null|    null|           null|       null|   null|               null|\n+----+--------------------+--------+--------------------+--------------------+--------+---------------+-----------+-------+-------------------+\nonly showing top 20 rows"
          },
          "execution_count": 4,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "DataFrame projectsDf = spark\n",
        "    .Read()\n",
        "    .Schema(\"id INT, url STRING, owner_id INT, \" +\n",
        "    \"name STRING, descriptor STRING, language STRING, \" +\n",
        "    \"created_at STRING, forked_from INT, deleted STRING, \" +\n",
        "    \"updated_at STRING\")\n",
        "    .Csv(\"<path_to_projects.csv>\");\n",
        "\n",
        "projectsDf.Show();"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean up our data\n",
        "Our data is all there, but it's looking a bit crowded. Let's do some **data prep** to clean up our data.\n",
        "\n",
        "### We can drop any rows with null entries."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {},
      "source": [
        "DataFrameNaFunctions dropEmptyProjects = projectsDf.Na();\n",
        "DataFrame cleanedProjects = dropEmptyProjects.Drop(\"any\");"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### We can also drop columns we won't need later.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "+--------------------+-----------+----------------+-----------+-------+-------------------+\n|                name|   language|      created_at|forked_from|deleted|         updated_at|\n+--------------------+-----------+----------------+-----------+-------+-------------------+\n|           ruote-kit|       Ruby| 12/8/2009 10:17|          2|      0|     11/5/2015 1:15|\n|           cocos2d-x|        C++| 3/12/2012 16:48|          6|      0|   10/22/2015 17:36|\n|           cocos2d-x|          C| 4/23/2012 10:20|          6|      0|    11/1/2015 17:32|\n|       rake-compiler|       Ruby|  8/1/2012 18:33|   14556189|      0|    11/3/2015 19:30|\n|    cobertura-plugin|       Java| 7/26/2012 18:46|     193522|      0|    11/1/2015 19:55|\n|     scala-vs-erlang|     Erlang|12/25/2011 13:51|    1262879|      0|    10/22/2015 4:50|\n|              opencv|        C++|  8/2/2012 12:50|         29|      0|    10/26/2015 6:44|\n| redmine_git_hosting|       Ruby| 7/30/2012 12:53|         42|      0|   10/28/2015 10:54|\n| redmine_git_hosting|       Ruby|10/26/2011 23:17|     207450|      0|   10/27/2015 22:43|\n|          OpenCV-iOS|Objective-C|  8/2/2012 12:55|         39|      1|0000-00-00 00:00:00|\n|           browserid| JavaScript| 6/30/2012 22:35|       1589|      0|    10/10/2015 0:34|\n|      protobuf-cmake|         \\N|  8/2/2012 14:35|         61|      0|    10/31/2015 1:22|\n|                loso|     Python|  8/2/2012 12:57|         67|      1|0000-00-00 00:00:00|\n|                yui3| JavaScript| 7/13/2012 14:48|         55|      1|0000-00-00 00:00:00|\n|         doctag_java|       Java|  8/2/2012 12:57|         70|      1|0000-00-00 00:00:00|\n|willdurand.github...| JavaScript|  8/2/2012 12:06|         84|      0|     11/4/2015 9:15|\n|            manaserv|        C++|  8/1/2011 17:05|         90|      0|    10/10/2015 4:42|\n|            manaserv|        C++| 3/24/2011 17:38|         90|      0|   10/16/2015 18:29|\n|               libuv|          C|  8/2/2012 12:57|         74|      0|    10/31/2015 8:21|\n|         cucumber-js| JavaScript| 5/28/2012 15:47|      10457|      1|0000-00-00 00:00:00|\n+--------------------+-----------+----------------+-----------+-------+-------------------+\nonly showing top 20 rows"
          },
          "execution_count": 6,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "cleanedProjects = cleanedProjects.Drop(\"id\", \"url\", \"owner_id\", \"descriptor\");\n",
        "cleanedProjects.Show();"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Now our data's looking better! Let's analyze this prepped data.\n",
        "We can group our projects by language, and then find the average number of times each project has been forked.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {},
      "source": [
        "DataFrame groupedDF = cleanedProjects\n",
        "    .GroupBy(\"language\")\n",
        "    .Agg(Avg(cleanedProjects[\"forked_from\"]));"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Let's order our data to have the top-forked projects first.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "+------------------+------------------+\n|          language|  avg(forked_from)|\n+------------------+------------------+\n|               GAP|         5497992.4|\n|              PAWN|         4883154.0|\n|               ooc|         4763738.5|\n|            Racket| 3868442.445652174|\n|              Haxe|3217677.3333333335|\n|               CSS|   2784979.3203125|\n|            Nimrod|       2662935.625|\n|                eC|         2304409.5|\n|              XSLT|      1638888.1875|\n|               Bro|1607539.3333333333|\n|              HTML|1554805.9310344828|\n|               TeX|1534278.6363636365|\n|             Logos|         1496027.5|\n|              VHDL|        1471550.25|\n|Ragel in Ruby Host|         1307989.5|\n|     SuperCollider|1301081.8666666667|\n|                Io|       1301006.875|\n|            Kotlin|         1233764.4|\n|           Ruby\"\"\"|         1151385.0|\n|               Ada|1149265.3333333333|\n+------------------+------------------+\nonly showing top 20 rows"
          },
          "execution_count": 8,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "groupedDF.OrderBy(Desc(\"avg(forked_from)\")).Show();"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We can use Spark SQL with user-defined functions (UDFs) and SQL calls in our notebooks, too!\n",
        "Let's use a UDF that will see if a given date comes after October 20, 2015.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First, we define our UDF, including the type of its input, output, and the functionality it performs.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {},
      "source": [
        "spark.Udf().Register<string, bool>(\n",
        "    \"BeforeOct\",\n",
        "    (date) => DateTime.TryParse(date, out DateTime convertedDate) &&\n",
        "        (convertedDate > (new DateTime(2015, 10, 20))));"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now that we have our UDF `BeforeOct` defined, we can call it on our prepped data.\n",
        "We can use **Spark SQL** to write a SQL call. It will call `BeforeOct` on each row of our DataFrame.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "+--------------------+-----------+----------------+-----------+-------+-------------------+----------+\n|                name|   language|      created_at|forked_from|deleted|         updated_at|datebefore|\n+--------------------+-----------+----------------+-----------+-------+-------------------+----------+\n|           ruote-kit|       Ruby| 12/8/2009 10:17|          2|      0|     11/5/2015 1:15|      true|\n|           cocos2d-x|        C++| 3/12/2012 16:48|          6|      0|   10/22/2015 17:36|      true|\n|           cocos2d-x|          C| 4/23/2012 10:20|          6|      0|    11/1/2015 17:32|      true|\n|       rake-compiler|       Ruby|  8/1/2012 18:33|   14556189|      0|    11/3/2015 19:30|      true|\n|    cobertura-plugin|       Java| 7/26/2012 18:46|     193522|      0|    11/1/2015 19:55|      true|\n|     scala-vs-erlang|     Erlang|12/25/2011 13:51|    1262879|      0|    10/22/2015 4:50|      true|\n|              opencv|        C++|  8/2/2012 12:50|         29|      0|    10/26/2015 6:44|      true|\n| redmine_git_hosting|       Ruby| 7/30/2012 12:53|         42|      0|   10/28/2015 10:54|      true|\n| redmine_git_hosting|       Ruby|10/26/2011 23:17|     207450|      0|   10/27/2015 22:43|      true|\n|          OpenCV-iOS|Objective-C|  8/2/2012 12:55|         39|      1|0000-00-00 00:00:00|     false|\n|           browserid| JavaScript| 6/30/2012 22:35|       1589|      0|    10/10/2015 0:34|     false|\n|      protobuf-cmake|         \\N|  8/2/2012 14:35|         61|      0|    10/31/2015 1:22|      true|\n|                loso|     Python|  8/2/2012 12:57|         67|      1|0000-00-00 00:00:00|     false|\n|                yui3| JavaScript| 7/13/2012 14:48|         55|      1|0000-00-00 00:00:00|     false|\n|         doctag_java|       Java|  8/2/2012 12:57|         70|      1|0000-00-00 00:00:00|     false|\n|willdurand.github...| JavaScript|  8/2/2012 12:06|         84|      0|     11/4/2015 9:15|      true|\n|            manaserv|        C++|  8/1/2011 17:05|         90|      0|    10/10/2015 4:42|     false|\n|            manaserv|        C++| 3/24/2011 17:38|         90|      0|   10/16/2015 18:29|     false|\n|               libuv|          C|  8/2/2012 12:57|         74|      0|    10/31/2015 8:21|      true|\n|         cucumber-js| JavaScript| 5/28/2012 15:47|      10457|      1|0000-00-00 00:00:00|     false|\n+--------------------+-----------+----------------+-----------+-------+-------------------+----------+\nonly showing top 20 rows\n\n+--------------------+----------+----------------+-----------+-------+----------------+----------+\n|                name|  language|      created_at|forked_from|deleted|      updated_at|datebefore|\n+--------------------+----------+----------------+-----------+-------+----------------+----------+\n|           ruote-kit|      Ruby| 12/8/2009 10:17|          2|      0|  11/5/2015 1:15|      true|\n|           cocos2d-x|       C++| 3/12/2012 16:48|          6|      0|10/22/2015 17:36|      true|\n|           cocos2d-x|         C| 4/23/2012 10:20|          6|      0| 11/1/2015 17:32|      true|\n|       rake-compiler|      Ruby|  8/1/2012 18:33|   14556189|      0| 11/3/2015 19:30|      true|\n|    cobertura-plugin|      Java| 7/26/2012 18:46|     193522|      0| 11/1/2015 19:55|      true|\n|     scala-vs-erlang|    Erlang|12/25/2011 13:51|    1262879|      0| 10/22/2015 4:50|      true|\n|              opencv|       C++|  8/2/2012 12:50|         29|      0| 10/26/2015 6:44|      true|\n| redmine_git_hosting|      Ruby| 7/30/2012 12:53|         42|      0|10/28/2015 10:54|      true|\n| redmine_git_hosting|      Ruby|10/26/2011 23:17|     207450|      0|10/27/2015 22:43|      true|\n|      protobuf-cmake|        \\N|  8/2/2012 14:35|         61|      0| 10/31/2015 1:22|      true|\n|willdurand.github...|JavaScript|  8/2/2012 12:06|         84|      0|  11/4/2015 9:15|      true|\n|               libuv|         C|  8/2/2012 12:57|         74|      0| 10/31/2015 8:21|      true|\n|         cucumber-js|JavaScript| 6/21/2012 11:47|         96|      0| 11/4/2015 21:42|      true|\n|             i18n-js|JavaScript|  8/2/2012 12:58|         92|      0|10/29/2015 13:19|      true|\n|               libuv|         C|  7/9/2012 12:56|         74|      0|10/31/2015 20:53|      true|\n|        angular-seed|JavaScript|  5/19/2012 6:30|        100|      0| 11/2/2015 14:21|      true|\n|           addon-sdk|    Python|11/29/2010 13:17|        127|      0|10/31/2015 20:10|      true|\n|   xinput_calibrator|       C++|  8/2/2012 12:59|        128|      0| 11/1/2015 14:27|      true|\n|           addon-sdk|JavaScript|  4/7/2011 17:58|        127|      0| 11/6/2015 11:03|      true|\n|                ntpl|    Python|  8/1/2012 16:50|        134|      0|10/25/2015 16:03|      true|\n+--------------------+----------+----------------+-----------+-------+----------------+----------+\nonly showing top 20 rows"
          },
          "execution_count": 10,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "cleanedProjects.CreateOrReplaceTempView(\"dateView\");\n",
        "\n",
        "DataFrame dateDf = spark.Sql(\n",
        "    \"SELECT *, BeforeOct(dateView.updated_at) AS datebefore FROM dateView\");\n",
        "\n",
        "dateDf.Show();\n",
        "\n",
        "DataFrame recentDf = dateDf.Filter(\"datebefore\");\n",
        "\n",
        "recentDf.Show();"
      ],
      "attachments": {}
    }
  ]
}
